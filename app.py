import streamlit as st
import json
import os
import pandas as pd
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(layout="centered", page_title="TechDocsBench: Human Review")

log_file = "human_eval_results.csv"

# --- –£–õ–£–ß–®–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê ---

def clean_markdown(text, is_api=False):
    """
    –ü–æ—Å—Ç—Ä–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–æ–≤ –±–µ–∑ –ø–æ–ª–æ–º–∫–∏ —Ç–∞–±–ª–∏—Ü.
    """
    if not isinstance(text, str): return text
    
    lines = text.split('\n')
    cleaned_lines = []
    
    in_code_block = False
    
    for line in lines:
        stripped = line.strip()
        
        # –°–ª–µ–¥–∏–º –∑–∞ –±–ª–æ–∫–∞–º–∏ –∫–æ–¥–∞
        if stripped.startswith('```'):
            in_code_block = not in_code_block
            cleaned_lines.append(line)
            continue
            
        if in_code_block:
            cleaned_lines.append(line)
            continue

        # 1. –ó–∞–º–µ–Ω—è–µ–º —Å–ø–µ—Ü-–±—É–ª–ª–∏—Ç—ã –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–æ–ª—å–∫–æ –≤–Ω–µ —Ç–∞–±–ª–∏—Ü
        if not stripped.startswith('|'):
            for sym in ['‚óè', '‚óã', '‚Ä¢', '¬∑']:
                line = line.replace(sym, '- ')
        
        # 2. –ï—Å–ª–∏ —ç—Ç–æ API-–∫–µ–π—Å, –º—ã –∫—Ä–∞–π–Ω–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã —Å –¥–µ—Ñ–∏—Å–∞–º–∏
        if not is_api:
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–ª–∏–ø –∫ —Ç–µ–∫—Å—Ç—É —Å–≤–µ—Ä—Ö—É
            if stripped.startswith('- ') or re.match(r'^\d+\.', stripped):
                if cleaned_lines and cleaned_lines[-1].strip() != "":
                    cleaned_lines.append("") # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ —Å–ø–∏—Å–∫–æ–º
        
        cleaned_lines.append(line)
        
    return "\n".join(cleaned_lines)

@st.cache_data
def load_all_results():
    data_map = {}
    files = [f for f in os.listdir('.') if f.startswith('results_') and f.endswith('.jsonl')]
    all_models = set()
    temp_list = []
    
    for file in files:
        with open(file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    item = json.loads(line)
                    temp_list.append(item)
                    all_models.add(item['model_name'])
                except: continue

    sorted_models = sorted(list(all_models))
    model_mapping = {m: f"–ú–æ–¥–µ–ª—å {chr(65+i)}" for i, m in enumerate(sorted_models)}

    unique_ids = []
    for item in temp_list:
        ex_id = item['meta']['id']
        if ex_id not in data_map:
            unique_ids.append(ex_id)
            data_map[ex_id] = {
                "title": item['meta']['original_title'],
                "input": item['input'],
                "reference": item['reference'],
                "task": item['task'],
                "outputs": {}
            }
        data_map[ex_id]["outputs"][item['model_name']] = item['model_output']
    
    case_navigation = {ex_id: f"–ö–µ–π—Å ‚Ññ{i+1}" for i, ex_id in enumerate(unique_ids)}
    return data_map, model_mapping, case_navigation, unique_ids

data, model_labels, case_nav, ordered_ids = load_all_results()

# --- –°–ê–ô–î–ë–ê–† ---
st.sidebar.title("–í—ã–±–æ—Ä –∫–µ–π—Å–æ–≤")
if os.path.exists(log_file):
    try:
        evaluated_ids = pd.read_csv(log_file)['example_id'].unique().tolist()
    except: evaluated_ids = []
else: evaluated_ids = []

default_index = 0
for i, ex_id in enumerate(ordered_ids):
    if ex_id not in evaluated_ids:
        default_index = i
        break

def label_maker(ex_id):
    status = "‚úÖ" if ex_id in evaluated_ids else "‚è≥"
    return f"{status} {case_nav[ex_id]}: {data[ex_id]['title']}"

selected_id = st.sidebar.selectbox("–ü—Ä–∏–º–µ—Ä", ordered_ids, index=default_index, format_func=label_maker)

st.sidebar.divider()
if os.path.exists(log_file):
    with open(log_file, "rb") as file:
        st.sidebar.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", file, "results.csv", "text/csv")

# --- –ö–û–ù–¢–ï–ù–¢ ---
item = data[selected_id]
is_api = (item['task'] == 'api_gen')
st.title(f"{case_nav[selected_id]}: {item['title']}")

if item['task'] == 'rewriting':
    st.subheader("‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
    st.markdown(clean_markdown(item['reference']))
else:
    t1, t2 = st.tabs(["üì• –ê—Ä—Ç–µ—Ñ–∞–∫—Ç", "‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç"])
    with t1:
        path = item['input'].replace('\\\\', '/').replace('\\', '/').strip()
        if path.lower().endswith('.png'):
            st.image(path, use_container_width=True) # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–∞ –≤—Å—é —à–∏—Ä–∏–Ω—É –≤–∫–ª–∞–¥–∫–∏
        elif path.lower().endswith('.md'):
            with open(path, 'r', encoding='utf-8') as f:
                st.code(f.read(), language='markdown')
        else: st.info(path)
    with t2:
        st.markdown(clean_markdown(item['reference'], is_api=is_api))

st.divider()

st.subheader("ü§ñ –û—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–µ–π")
for m_name in sorted(list(item['outputs'].keys())):
    label = model_labels[m_name]
    with st.expander(f"üìÑ {label}", expanded=True):
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ü–û–õ–ù–´–ô —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–±—Ä–µ–∑–∞–Ω–∏—è
        st.markdown(clean_markdown(item['outputs'][m_name], is_api=is_api))

st.divider()

# --- –§–û–†–ú–ê ---
with st.form(key=f"f_{selected_id}"):
    st.write("–û—Ü–µ–Ω–∫–∞ (1-5):")
    criteria = ["–Ø—Å–Ω–æ—Å—Ç—å", "–¢–æ—á–Ω–æ—Å—Ç—å", "–ü–æ–ª–Ω–æ—Ç–∞", "–ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ", "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "–ò–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å"]
    available_models = sorted(list(item['outputs'].keys()))
    
    cols = st.columns([1.5] + [1]*len(available_models))
    cols[0].write("**–ö—Ä–∏—Ç–µ—Ä–∏–π**")
    for i, m_name in enumerate(available_models):
        cols[i+1].write(f"**{model_labels[m_name]}**")
    
    scores = {}
    for crit in criteria:
        r = st.columns([1.5] + [1]*len(available_models))
        r[0].write(crit)
        for i, m_name in enumerate(available_models):
            if m_name not in scores: scores[m_name] = {}
            scores[m_name][crit] = r[i+1].selectbox("B", [1,2,3,4,5], index=4, key=f"s_{selected_id}_{m_name}_{crit}", label_visibility="collapsed")
            
    comment = st.text_area("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", key=f"comm_{selected_id}")
    if st.form_submit_button("üöÄ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫–∏"):
        recs = []
        for m_name, scs in scores.items():
            d = {"example_id": selected_id, "model": m_name, "comment": comment}
            d.update(scs)
            recs.append(d)
        pd.DataFrame(recs).to_csv(log_file, mode='a', index=False, header=not os.path.exists(log_file))
        st.cache_data.clear()
        st.rerun()